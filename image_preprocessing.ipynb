{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34af0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f91bfb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class digitRecognizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(digitRecognizer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = digitRecognizer()\n",
    "model.load_state_dict(torch.load('nist_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "702aa565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing images of digits for better recognition\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((10,10)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "def process(image,x,y,w,h):\n",
    "    padding=9\n",
    "    threshold=0.95\n",
    "    result = image[y:y+h, x:x+w]\n",
    "    result=F.pad(transform(torch.from_numpy(result).unsqueeze(0)).squeeze(), (padding, padding, padding, padding), mode='constant',value=1.)\n",
    "    result=F.threshold(result, threshold, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87d6a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(img):\n",
    "    model.eval()\n",
    "    model.double()\n",
    "    if type(img)==str:\n",
    "        image = cv2.imread(img)\n",
    "    else:\n",
    "        image=img\n",
    "    #grayscaling and threshold\n",
    "    img_grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(img_grey, 200, 255, cv2.THRESH_BINARY)\n",
    "    #finding contours \n",
    "    contours, hierarchy = cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "    #removing contours that are not primary and removing the boundary of the whole image\n",
    "    i=0\n",
    "    while i<len(contours):\n",
    "        if hierarchy[0][i][3]!=0 :\n",
    "            contours=contours[:i]+contours[i+1:]\n",
    "            hierarchy=np.array([np.delete(hierarchy[0],i,0)])\n",
    "        else:\n",
    "            i+=1\n",
    "    #defining bounding boxes and centers for each digit\n",
    "    rectangles=[]\n",
    "    centers=[]\n",
    "    for i in contours:\n",
    "        rectangles.append(cv2.boundingRect(i))\n",
    "    for (x,y,w,h) in rectangles:\n",
    "        centers.append((x+(h+w)/2,y+(h+w)/2))\n",
    "    #detecting bounding boxes that are too close using dbscan clustering to detect digits that are from the same multi-digit number\n",
    "    w_mean=np.array([w for (x,y,w,h) in rectangles]).mean()\n",
    "    dbscan = DBSCAN(eps=2.1*w_mean, min_samples=0)\n",
    "    labels = dbscan.fit_predict(centers)\n",
    "    #There are len(labels.unique()) numbers in the image\n",
    "    nbr=len(set(labels))\n",
    "    #a dictionnary with the x coordinate of each digit and its label to reconstitute the numbers in the correct order\n",
    "    labels=dict(zip([rectangle[0] for rectangle in rectangles],labels))\n",
    "    #dictionnary for predictions \n",
    "    preds={}\n",
    "    #fill it with predictions\n",
    "    for (x,y,w,h) in rectangles:\n",
    "        to_analyse=process(img_grey,x,y,w,h)\n",
    "        outputs=model(to_analyse.unsqueeze(0).double())\n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        preds[x]=predicted.item()\n",
    "    # Use defaultdict to group keys by their values\n",
    "    grouped_labels = defaultdict(list)\n",
    "    for k, v in labels.items():\n",
    "        grouped_labels[v].append(k)\n",
    "    # Sort the keys within each group and print the results\n",
    "    for v, keys in grouped_labels.items():\n",
    "        keys_sorted = sorted(keys)\n",
    "        for i in range (len(keys_sorted)):\n",
    "            keys_sorted[i]=preds[keys_sorted[i]]\n",
    "        grouped_labels[v]=''.join(map(str, keys_sorted))\n",
    "    print('There are {} numbers in this image:'.format(nbr))\n",
    "    for v, preds in grouped_labels.items():\n",
    "        print(preds)\n",
    "    return [int(preds) for v, preds in grouped_labels.items()]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c32ce771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 numbers in this image:\n",
      "87536\n",
      "99\n",
      "15\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[87536, 99, 15, 20]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read('example.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f50ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
